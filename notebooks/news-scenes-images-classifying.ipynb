{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新闻场景截图的分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入全局代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "from glob import glob\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常量定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 普通常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "DATA_DIR = '../data/images/dev'\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 60\n",
    "LEARNING_RATE = 1e-5\n",
    "INPUT_SIZE = 224\n",
    "DATA_PARALLEL = False\n",
    "\n",
    "phases = ['train', 'val']\n",
    "\n",
    "# Flag for feature extracting.\n",
    "#   - When False, we finetune the whole model,\n",
    "#   - when True we only update the reshaped layer params\n",
    "feature_extract = True\n",
    "\n",
    "# 模型种类，输出路径\n",
    "model_export_dir = 'out'\n",
    "model_name = \"squeezenet1_0\"\n",
    "model_export_file = os.path.join(model_export_dir, '{0}-{1}-py{2[0]}{2[1]}.pkl'.format(model_name, INPUT_SIZE, sys.version_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图形变形器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torchvision` 预训练模型的的数据相当的“硬核”，其转换方式如下:\n",
    "\n",
    "> **ℹ Tips:**\n",
    ">\n",
    "> 使用 [`torchvision.datasets.ImageFolder`](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.ImageFolder) 这个类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(INPUT_SIZE),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(INPUT_SIZE),\n",
    "        transforms.CenterCrop(INPUT_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 加载训练数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageFolder 加载和分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_int_by_rates(i, percents):\n",
    "    if not isinstance(i, int):\n",
    "        raise TypeError(f'Expected type of argument `i` is `int`, but `{type(i)}` actually')\n",
    "    if i < 0:\n",
    "        raise ValueError('Argument `i` can not be smaller than zero')\n",
    "    if sum(percents) >= 1.0:\n",
    "        raise ValueError('Sum of percents can not be greater than or equal to `1.0`')\n",
    "    result = []\n",
    "    for percent in percents:\n",
    "        result.append(math.trunc(i * percent))\n",
    "    result.append(i - sum(result))\n",
    "    return result\n",
    "\n",
    "print(\"初始化：数据集 数据加载器 ...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "images_dataset = datasets.ImageFolder(DATA_DIR)\n",
    "lengths = decompose_int_by_rates(len(images_dataset), [.9,])\n",
    "datasets_dict = {\n",
    "    phase: subset\n",
    "    for phase, subset in zip(phases, random_split(images_dataset, lengths))\n",
    "}\n",
    "for phase, sebset in datasets_dict.items():\n",
    "    sebset.dataset.transform = data_transforms[phase]\n",
    "\n",
    "display(pd.DataFrame(\n",
    "    {'name': x, 'size': len(subset)}\n",
    "    for x, subset in datasets_dict.items()\n",
    "))\n",
    "\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {\n",
    "    x: DataLoader(\n",
    "        datasets_dict[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4\n",
    "    )\n",
    "    for x in phases\n",
    "}\n",
    "\n",
    "classes = images_dataset.classes\n",
    "num_classes = len(classes)\n",
    "\n",
    "display(pd.DataFrame({\n",
    "    '图片分类': classes\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchvision 张量转 matplotlib 数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torchim_show(image_tensor, show=True, pause=0.001):\n",
    "    pause = float(pause)\n",
    "    image_tensor_denormalized = (image_tensor + 1) / 2\n",
    "    image_array = image_tensor_denormalized.numpy().transpose(1, 2, 0)\n",
    "    if show:\n",
    "        plt.imshow(image_array)\n",
    "        if pause > 0:\n",
    "            plt.pause(pause)\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示一批训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, labels in dataloaders_dict['train']:\n",
    "    batch_size = inputs.size(0)\n",
    "    for i in range(batch_size):\n",
    "        label = labels[i].item()\n",
    "        img = inputs[i]\n",
    "        print(classes[label])\n",
    "        torchim_show(img)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## GPU / CPU 设备\n",
    "\n",
    "就像将Tensor转到GPU一样，可将神经网络转到GPU。\n",
    "\n",
    "如果有可用的CUDA，我们首先获取第一个可见的cuda设备："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 帮助函数定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 模型的训练/验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, dataloaders, criterion, optimizer, epochs, is_inception=False, predict_value_threshold=None):\n",
    "    since = time.time()\n",
    "\n",
    "    history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = -1\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_desc = f'Epoch {epoch+1}/{epochs}'\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "            \n",
    "            # detect batch size\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                batch_size = inputs.size(0)\n",
    "                break\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels) in tqdm(\n",
    "                enumerate(dataloaders[phase]),\n",
    "                desc=f'{epoch_desc} - {phase}',\n",
    "                total=math.ceil(len(dataloaders[phase].dataset) / batch_size),\n",
    "                unit='batch(s)'\n",
    "            ):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    pred_values, pred_indeces = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += sum(\n",
    "                    pred_index == label\n",
    "                    for pred_value, pred_index, label\n",
    "                    in zip(*(m.tolist() for m in (pred_values, pred_indeces, labels)))\n",
    "                    if (predict_value_threshold is None) or (pred_value >= predict_value_threshold)\n",
    "                )\n",
    "               \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n",
    "            history.append({\n",
    "                'epoch': epoch,\n",
    "                'phase': phase,\n",
    "                'acc': epoch_acc,\n",
    "                'loss': epoch_loss,\n",
    "            })\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val':\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_epoch = epoch\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                best_acc_check_symbol = f\"{'✔' if best_epoch == epoch else '✖'}\"\n",
    "                print(\n",
    "                    f'{epoch_desc} - {phase}  Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}  best({best_acc_check_symbol})'\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    f'{epoch_desc} - {phase}  Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}'\n",
    "                )\n",
    "        print()\n",
    "\n",
    "    print(f'Training complete in {timedelta(seconds=time.time() - since)}')\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置模型参数的 `.requires_grad` 属性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置为 `False` 表示正在进行 **feature extracting**。\n",
    "\n",
    "一般来说，预训练模型的所有参数均是 `.requires_grad=True`。\n",
    "\n",
    "但是我们在  **feature extracting** 时，只需要对新初始化的层进行梯度计算，所以要让这些参数与要计算的梯度无关。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 神经网络的初始化和改造"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型的初始化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = INPUT_SIZE\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = INPUT_SIZE\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = INPUT_SIZE\n",
    "\n",
    "    elif model_name == \"squeezenet1_0\":\n",
    "        \"\"\" Squeezenet 1.0\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = INPUT_SIZE\n",
    "\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 执行模型的初始化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_inception = model_name==\"inception\"\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "if device != 'cpu':\n",
    "    # parallel model\n",
    "    if DATA_PARALLEL:\n",
    "        model_ft = nn.DataParallel(model_ft)\n",
    "    # Send the model to GPU if have one\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "print('Model: ', model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=LEARNING_RATE, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 执行训练和验证步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 执行训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, device, dataloaders_dict, criterion, optimizer_ft, NUM_EPOCHS, is_inception, predict_value_threshold=6.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(hist)\n",
    "\n",
    "df_val_hist = df.loc[df['phase']=='val']\n",
    "\n",
    "plot_acc = df.hvplot.line(x='epoch', y='acc', by='phase').opts(title='acc')\n",
    "plot_best_val_acc = df_val_hist.loc[df_val_hist.index == df_val_hist['acc'].idxmax()] \\\n",
    "    .hvplot.scatter(x='epoch', y='acc', size=100, alpha=0.5)\n",
    "plot_loss = df.hvplot.line(x='epoch', y='loss', by='phase').opts(title='loss')\n",
    "\n",
    "\n",
    "hv.Layout(plot_acc * plot_best_val_acc + plot_loss).cols(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存模型到文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_export_dir, exist_ok=True)\n",
    "\n",
    "print('save model_ft to: ', model_export_file)\n",
    "\n",
    "torch.save(model_ft, model_export_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从文件载入模型\n",
    "\n",
    "> **❗ Note:**\n",
    ">\n",
    "> 如果不想重新训练，且之前已经保存了模型，可以从这里开始！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == 'cpu':\n",
    "    model_ft = torch.load(model_export_file, map_location='cpu')\n",
    "    if isinstance(model_ft, nn.DataParallel):\n",
    "        model_ft = model_ft.module\n",
    "else:\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model_ft = torch.load(model_export_file)\n",
    "        model_ft = model_ft.to(device)\n",
    "\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测一个图片试试看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, device, image_tensor):\n",
    "    with torch.no_grad():\n",
    "        model = model.eval()\n",
    "        batched_samples = torch.tensor([np.array(image_tensor)]).to(device)    \n",
    "        outputs = model(batched_samples)\n",
    "    return [m.item() for m in outputs[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_by_url(url):\n",
    "    image = skimage.io.imread(url)\n",
    "    tsfrm = data_transforms['val']\n",
    "    sample = tsfrm(transforms.ToPILImage()(image))\n",
    "#     skimage.io.imshow(image)\n",
    "#     plt.pause(0.001)\n",
    "    torchim_show(sample)\n",
    "    plt.pause(0.001)\n",
    "    scores = predict_image(model_ft, device, sample)\n",
    "    sum_prob = sum(scores)\n",
    "    display(\n",
    "        pd.DataFrame(\n",
    "            {'class': s, 'score': score, 'prob': score/sum_prob}\n",
    "            for s, score in zip(classes, scores)\n",
    "        ).sort_values(by=['score'], ascending=False)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测人工选择的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '/home/Public/jxdaily-scenes-split/data/images/湖口/20190520.eval/'\n",
    "\n",
    "files = [\n",
    "    # 无字幕\n",
    "    '湖口-20190520-66_3.jpg',\n",
    "    # 有字幕\n",
    "    '湖口-20190520-23_3.jpg',\n",
    "    # '播音室'\n",
    "    '湖口-20190520-19_1.jpg',\n",
    "]\n",
    "\n",
    "for fn in files:\n",
    "    file_path = os.path.join(dir_path, fn)\n",
    "    predict_image_by_url(file_path)\n",
    "    print('-----------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测随机数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = glob('/home/Public/jxdaily-scenes-split/data/images/湖口/20190520.eval/*.jpg')\n",
    "files = random.choices(image_files, k=10)\n",
    "\n",
    "ts = time.time()\n",
    "\n",
    "for fn in files:\n",
    "    predict_image_by_url(fn)\n",
    "    print('-----------------------------')\n",
    "\n",
    "print(timedelta(seconds=time.time()-ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测域外数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用湖口的模型硬上，预测瑞昌的抓图:\n",
    "\n",
    "predict_image_by_url('/home/Public/jxdaily-scenes-split/data/vlcsnap-2019-05-22-18h17m05s583.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用湖口的模型硬上，预测瑞昌的抓图:\n",
    "\n",
    "predict_image_by_url('/home/Public/jxdaily-scenes-split/data/vlcsnap-2019-05-24-16h08m29s390.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用湖口的模型硬上，预测广昌的抓图:\n",
    "\n",
    "predict_image_by_url('/home/Public/jxdaily-scenes-split/data/vlcsnap-2019-05-24-16h13m58s190.png')\n",
    "predict_image_by_url('/home/Public/jxdaily-scenes-split/data/vlcsnap-2019-05-24-16h15m36s078.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jxcn-newsvideo-poc]",
   "language": "python",
   "name": "conda-env-jxcn-newsvideo-poc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
